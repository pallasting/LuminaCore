#!/usr/bin/env python3
"""
Dynamic Load Balancer

åŠ¨æ€è´Ÿè½½å‡è¡¡å™¨ - æ ¹æ®ç“¦ç‰‡åˆ©ç”¨ç‡åŠ¨æ€è°ƒæ•´å±‚åˆ†é…

å·¥ä½œåŸç†:
1. ç›‘æ§æ¯ä¸ªç“¦ç‰‡çš„æ‰§è¡Œæ—¶é—´
2. æ£€æµ‹è´Ÿè½½ä¸å‡è¡¡ (æŸç“¦ç‰‡æ‰§è¡Œæ—¶é—´æ˜æ˜¾æ›´é•¿)
3. åŠ¨æ€é‡æ–°åˆ†é…å±‚åˆ°ä¸åŒç“¦ç‰‡
4. é‡æ–°å¹³è¡¡åç»§ç»­æ‰§è¡Œ
"""

import torch
import time
import threading
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, field
from collections import defaultdict
import numpy as np
import lumina_kernel


@dataclass
class TileMetrics:
    """ç“¦ç‰‡æŒ‡æ ‡"""
    tile_id: str
    total_time: float = 0.0
    task_count: int = 0
    avg_task_time: float = 0.0
    current_load: float = 0.0  # å½“å‰è´Ÿè½½ (0-1)
    temperature: float = 25.0  # æ¨¡æ‹Ÿæ¸©åº¦ (Â°C)
    noise_level: float = 0.01


@dataclass
class LoadBalancingConfig:
    """è´Ÿè½½å‡è¡¡é…ç½®"""
    check_interval: int = 5  # æ¯ N ä¸ªä»»åŠ¡æ£€æŸ¥ä¸€æ¬¡
    imbalance_threshold: float = 0.2  # 20% ä¸å‡è¡¡é˜ˆå€¼
    max_rebalancing: int = 3  # æœ€å¤§é‡å¹³è¡¡æ¬¡æ•°
    cooldown_time: float = 1.0  # é‡å¹³è¡¡å†·å´æ—¶é—´
    temperature_threshold: float = 80.0  # æ¸©åº¦é˜ˆå€¼


class DynamicLoadBalancer:
    """
    åŠ¨æ€è´Ÿè½½å‡è¡¡å™¨

    ç‰¹ç‚¹:
    - å®æ—¶ç›‘æ§ç“¦ç‰‡åˆ©ç”¨ç‡
    - åŸºäºæ‰§è¡Œæ—¶é—´è‡ªåŠ¨é‡å¹³è¡¡
    - è€ƒè™‘æ¸©åº¦å’Œå™ªå£°å½±å“
    - çº¿ç¨‹å®‰å…¨
    """

    def __init__(
        self,
        num_tiles: int = 4,
        config: Optional[LoadBalancingConfig] = None
    ):
        self.num_tiles = num_tiles
        self.config = config or LoadBalancingConfig()

        # ç“¦ç‰‡æŒ‡æ ‡
        self.tiles: Dict[str, TileMetrics] = {
            f"Tile-{i}": TileMetrics(tile_id=f"Tile-{i}")
            for i in range(num_tiles)
        }

        # ä»»åŠ¡å†å²
        self.task_history: List[Dict[str, Any]] = []

        # é‡å¹³è¡¡çŠ¶æ€
        self.rebalance_count = 0
        self.last_rebalance_time = 0
        self.current_assignment: Dict[str, List[int]] = {}

        # é”
        self.lock = threading.Lock()

        # æƒé‡åˆ†é…
        self.layer_weights: Dict[int, float] = {}  # æ¯å±‚çš„è®¡ç®—å¤æ‚åº¦

        print(f"ğŸš€ DynamicLoadBalancer åˆå§‹åŒ–")
        print(f"   ç“¦ç‰‡æ•°: {num_tiles}")
        print(f"   ä¸å‡è¡¡é˜ˆå€¼: {self.config.imbalance_threshold*100:.0f}%")

    def set_layer_weights(self, weights: Dict[int, float]):
        """è®¾ç½®æ¯å±‚çš„è®¡ç®—å¤æ‚åº¦æƒé‡"""
        self.layer_weights = weights

    def _get_assignment_from_weights(self, num_layers: int) -> Dict[str, List[int]]:
        """æ ¹æ®æƒé‡åˆ†é…å±‚åˆ°ç“¦ç‰‡"""
        # æŒ‰æƒé‡æ’åº
        sorted_layers = sorted(range(num_layers), key=lambda i: self.layer_weights.get(i, 1.0))

        # è½®è¯¢åˆ†é…åˆ°æœ€ç©ºé—²çš„ç“¦ç‰‡
        assignment: Dict[str, List[int]] = {f"Tile-{i}": [] for i in range(self.num_tiles)}
        tile_loads = [0.0] * self.num_tiles

        for layer_idx in sorted_layers:
            weight = self.layer_weights.get(layer_idx, 1.0)
            # æ‰¾åˆ°è´Ÿè½½æœ€å°çš„ç“¦ç‰‡
            min_load_idx = min(range(self.num_tiles), key=lambda i: tile_loads[i])
            assignment[f"Tile-{min_load_idx}"].append(layer_idx)
            tile_loads[min_load_idx] += weight

        return assignment

    def record_task_completion(
        self,
        tile_id: str,
        layer_idx: int,
        execution_time: float,
        task_id: int = 0
    ):
        """è®°å½•ä»»åŠ¡å®Œæˆ"""
        with self.lock:
            # æ›´æ–°ç“¦ç‰‡æŒ‡æ ‡
            tile = self.tiles[tile_id]
            tile.task_count += 1
            tile.total_time += execution_time
            tile.avg_task_time = tile.total_time / tile.task_count

            # è®°å½•ä»»åŠ¡å†å²
            self.task_history.append({
                "tile_id": tile_id,
                "layer_idx": layer_idx,
                "execution_time": execution_time,
                "timestamp": time.time(),
                "task_id": task_id
            })

            # ä¿æŒå†å²åœ¨åˆç†èŒƒå›´
            if len(self.task_history) > 1000:
                self.task_history = self.task_history[-500:]

    def check_imbalance(self) -> Optional[Dict[str, Any]]:
        """æ£€æŸ¥è´Ÿè½½ä¸å‡è¡¡"""
        if len(self.task_history) < self.config.check_interval:
            return None

        # è®¡ç®—æ¯ä¸ªç“¦ç‰‡çš„å¹³å‡ä»»åŠ¡æ—¶é—´
        tile_times: Dict[str, float] = {}
        for tile in self.tiles.values():
            tile_times[tile.tile_id] = tile.avg_task_time

        if not tile_times:
            return None

        # è®¡ç®—ä¸å‡è¡¡åº¦
        avg_time = sum(tile_times.values()) / len(tile_times)
        max_time = max(tile_times.values())
        min_time = min(tile_times.values())

        if avg_time == 0:
            return None

        imbalance = (max_time - min_time) / avg_time

        if imbalance > self.config.imbalance_threshold:
            # æ‰¾åˆ°æœ€å¿™å’Œæœ€é—²çš„ç“¦ç‰‡
            busiest = max(tile_times.items(), key=lambda x: x[1])
            slowest = min(tile_times.items(), key=lambda x: x[1])

            return {
                "imbalance": imbalance,
                "busiest_tile": busiest[0],
                "busiest_time": busiest[1],
                "slowest_tile": slowest[0],
                "slowest_time": slowest[1],
                "avg_time": avg_time
            }

        return None

    def rebalance(self, num_layers: int) -> Dict[str, List[int]]:
        """
        æ‰§è¡Œè´Ÿè½½é‡å¹³è¡¡

        Returns:
            æ–°çš„åˆ†é…æ–¹æ¡ˆ
        """
        if self.rebalance_count >= self.config.max_rebalancing:
            print(f"   âš ï¸ è¾¾åˆ°æœ€å¤§é‡å¹³è¡¡æ¬¡æ•° ({self.config.max_rebalancing})")
            return self.current_assignment

        # æ£€æŸ¥å†·å´æ—¶é—´
        if time.time() - self.last_rebalance_time < self.config.cooldown_time:
            return self.current_assignment

        print(f"\nğŸ”„ æ‰§è¡Œè´Ÿè½½é‡å¹³è¡¡ (ç¬¬ {self.rebalance_count + 1} æ¬¡)...")

        # åˆ†æä»»åŠ¡å†å²ï¼Œè®¡ç®—å®é™…è´Ÿè½½
        layer_loads: Dict[int, float] = defaultdict(float)
        for task in self.task_history[-100:]:
            layer_loads[task["layer_idx"]] += task["execution_time"]

        # å¹³å‡åŒ–è´Ÿè½½
        num_tasks = max(1, len(self.task_history) // self.num_tiles)
        for layer_idx in layer_loads:
            layer_loads[layer_idx] /= num_tasks

        # æ›´æ–°å±‚æƒé‡
        self.layer_weights = dict(layer_loads)

        # ç”Ÿæˆæ–°åˆ†é…
        new_assignment = self._get_assignment_from_weights(num_layers)

        # è®¡ç®—è´Ÿè½½å˜åŒ–
        old_loads = self._calculate_assignment_load(self.current_assignment)
        new_loads = self._calculate_assignment_load(new_assignment)

        old_imbalance = max(old_loads.values()) - min(old_loads.values()) if old_loads else 0
        new_imbalance = max(new_loads.values()) - min(new_loads.values()) if new_loads else 0

        print(f"   æ—§è´Ÿè½½å·®å¼‚: {old_imbalance:.3f}s")
        print(f"   æ–°è´Ÿè½½å·®å¼‚: {new_imbalance:.3f}s")

        if new_imbalance < old_imbalance or not self.current_assignment:
            self.current_assignment = new_assignment
            self.rebalance_count += 1
            self.last_rebalance_time = time.time()

            print(f"   âœ… é‡å¹³è¡¡å®Œæˆ")
            return new_assignment
        else:
            print(f"   âš ï¸ é‡å¹³è¡¡æ— æ”¹å–„ï¼Œè·³è¿‡")
            return self.current_assignment

    def _calculate_assignment_load(self, assignment: Dict[str, List[int]]) -> Dict[str, float]:
        """è®¡ç®—åˆ†é…æ–¹æ¡ˆçš„è´Ÿè½½"""
        loads: Dict[str, float] = {}
        for tile_id, layers in assignment.items():
            total_load = sum(self.layer_weights.get(i, 0) for i in layers)
            loads[tile_id] = total_load
        return loads

    def get_status(self) -> Dict[str, Any]:
        """è·å–å½“å‰çŠ¶æ€"""
        with self.lock:
            return {
                "tiles": {
                    tile_id: {
                        "task_count": metrics.task_count,
                        "avg_time": metrics.avg_task_time,
                        "current_load": metrics.current_load,
                        "temperature": metrics.temperature
                    }
                    for tile_id, metrics in self.tiles.items()
                },
                "rebalance_count": self.rebalance_count,
                "task_history_size": len(self.task_history)
            }

    def print_status(self):
        """æ‰“å°å½“å‰çŠ¶æ€"""
        status = self.get_status()
        print(f"\nğŸ“Š Load Balancer Status:")
        print(f"   æ€»ä»»åŠ¡æ•°: {sum(t['task_count'] for t in status['tiles'].values())}")
        print(f"   é‡å¹³è¡¡æ¬¡æ•°: {status['rebalance_count']}")

        print(f"\nğŸ“± Tile Utilization:")
        for tile_id, info in status["tiles"].items():
            load_bar = "â–ˆ" * int(info["current_load"] * 20)
            print(f"   {tile_id}: {info['task_count']:3d} tasks, "
                  f"avg {info['avg_time']*1000:6.2f}ms, "
                  f"temp {info['temperature']:.1f}Â°C")


class LoadBalancedExecutor:
    """æ”¯æŒè´Ÿè½½å‡è¡¡çš„æ‰§è¡Œå™¨"""

    def __init__(
        self,
        num_tiles: int = 4,
        use_rust: bool = True
    ):
        self.num_tiles = num_tiles
        self.use_rust = use_rust
        self.balancer = DynamicLoadBalancer(num_tiles)
        self.current_assignment: Dict[str, List[int]] = {}

        # åˆå§‹åŒ–è®¾å¤‡
        for i in range(num_tiles):
            device_name = f"Tile-{i}"
            if device_name not in lumina_kernel.list_devices():
                lumina_kernel.create_mock_device(device_name, 8 * 1024**3)

        print(f"ğŸš€ LoadBalancedExecutor åˆå§‹åŒ–å®Œæˆ")

    def execute_with_balancing(
        self,
        input_tensor: torch.Tensor,
        weights: Dict[int, torch.Tensor],
        num_batches: int = 4
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œå¸¦è´Ÿè½½å‡è¡¡çš„æ¨ç†

        Returns:
            æ‰§è¡Œç»“æœå’Œæ€§èƒ½æŒ‡æ ‡
        """
        num_layers = len(weights)

        # åˆå§‹åˆ†é… (å¹³å‡åˆ†é…)
        layers_per_tile = num_layers // self.num_tiles
        self.current_assignment = {
            f"Tile-{i}": list(range(i * layers_per_tile, min((i + 1) * layers_per_tile, num_layers)))
            for i in range(self.num_tiles)
        }

        print(f"\nâš¡ å¼€å§‹å¸¦è´Ÿè½½å‡è¡¡çš„æ¨ç†")
        print(f"   ç“¦ç‰‡æ•°: {self.num_tiles}")
        print(f"   æ‰¹æ¬¡: {num_batches}")

        # åˆå§‹åŒ–è´Ÿè½½å‡è¡¡å™¨
        self.balancer.current_assignment = self.current_assignment

        results = []
        start_time = time.time()

        for batch_idx in range(num_batches):
            output = input_tensor
            batch_tasks = []

            # åœ¨æ¯ä¸ªç“¦ç‰‡ä¸Šæ‰§è¡Œ
            for tile_id, layers in self.current_assignment.items():
                tile_start = time.time()

                for layer_idx in layers:
                    weight = weights[layer_idx]

                    if self.use_rust:
                        # Rust åç«¯
                        output_np = lumina_kernel.optical_linear_fused(
                            output.detach().cpu().numpy(),
                            weight.detach().cpu().numpy(),
                            None, 0.01, 8,
                            seed=42 + layer_idx + batch_idx * 100
                        )
                        output = torch.from_numpy(output_np)
                    else:
                        # PyTorch
                        output = torch.nn.functional.linear(output, weight)

                    exec_time = time.time() - tile_start

                    # è®°å½•ä»»åŠ¡å®Œæˆ
                    self.balancer.record_task_completion(
                        tile_id, layer_idx, exec_time,
                        task_id=batch_idx * num_layers + layer_idx
                    )

                batch_tasks.append({
                    "tile_id": tile_id,
                    "time": time.time() - tile_start,
                    "layers": len(layers)
                })

            results.append({
                "batch_idx": batch_idx,
                "output": output,
                "tasks": batch_tasks,
                "time": time.time() - start_time
            })

            # æ£€æŸ¥è´Ÿè½½å‡è¡¡
            imbalance = self.balancer.check_imbalance()
            if imbalance:
                print(f"   âš ï¸ æ£€æµ‹åˆ°è´Ÿè½½ä¸å‡è¡¡: {imbalance['imbalance']*100:.1f}%")
                new_assignment = self.balancer.rebalance(num_layers)
                if new_assignment:
                    self.current_assignment = new_assignment

        total_time = time.time() - start_time

        return {
            "results": results,
            "total_time": total_time,
            "throughput": num_batches / total_time,
            "balancer_status": self.balancer.get_status()
        }


def demo_load_balancing():
    """æ¼”ç¤ºè´Ÿè½½å‡è¡¡"""
    print("=" * 70)
    print("Dynamic Load Balancing Demo")
    print("=" * 70)

    # é…ç½®
    num_layers = 12
    hidden_size = 2048
    num_batches = 8

    # åˆ›å»ºæ¨¡å‹ (æ‰€æœ‰å±‚ç›¸åŒå¤§å°ï¼Œä½†æ¨¡æ‹Ÿä¸åŒè®¡ç®—å¤æ‚åº¦)
    weights = {}
    for i in range(num_layers):
        # æ¨¡æ‹Ÿä¸åŒå±‚çš„è®¡ç®—å¤æ‚åº¦ (ä¸­é—´å±‚éœ€è¦æ›´é•¿æ—¶é—´)
        if 4 <= i <= 7:
            # ä¸­é—´å±‚ï¼šæ·»åŠ æ›´å¤šæ“ä½œæ¥æ¨¡æ‹Ÿå¤æ‚è®¡ç®—
            weights[i] = torch.randn(hidden_size, hidden_size)
        else:
            weights[i] = torch.randn(hidden_size, hidden_size)

    # åˆ›å»ºæµ‹è¯•æ‰¹æ¬¡
    test_batches = [
        torch.randn(2, hidden_size)
        for _ in range(num_batches)
    ]

    # æ‰§è¡Œå¸¦è´Ÿè½½å‡è¡¡çš„æ¨ç†
    executor = LoadBalancedExecutor(num_tiles=4)

    result = executor.execute_with_balancing(
        test_batches[0], weights, num_batches
    )

    # æ‰“å°ç»“æœ
    print(f"\n" + "=" * 70)
    print("ğŸ“Š Results")
    print("=" * 70)
    print(f"   æ€»æ—¶é—´: {result['total_time']:.3f}s")
    print(f"   ååé‡: {result['throughput']:.2f} batches/s")

    status = result['balancer_status']
    print(f"\nğŸ“± Tile Utilization:")
    for tile_id, info in status["tiles"].items():
        print(f"   {tile_id}: {info['task_count']} tasks, "
              f"avg {info['avg_time']*1000:.2f}ms")

    print(f"\n   é‡å¹³è¡¡æ¬¡æ•°: {status['rebalance_count']}")

    print(f"\n" + "=" * 70)


if __name__ == "__main__":
    demo_load_balancing()
