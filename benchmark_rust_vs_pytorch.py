#!/usr/bin/env python3
"""
æ€§èƒ½åŸºå‡†æµ‹è¯•ï¼šPyTorch vs Rust åç«¯

å¯¹æ¯” LuminaFlow SDK çš„ PyTorch å®ç°å’Œ Rust åŠ é€Ÿåç«¯çš„æ€§èƒ½
"""

import time
import numpy as np
import torch
import torch.nn.functional as F
from typing import Dict, List, Tuple

# å°è¯•å¯¼å…¥ Rust åç«¯
try:
    import lumina_kernel
    RUST_AVAILABLE = True
except ImportError:
    RUST_AVAILABLE = False
    print("âš ï¸  Rust åç«¯æœªå®‰è£…ï¼Œå°†åªæµ‹è¯• PyTorch åŸºçº¿")
    print("ğŸ’¡ æç¤º: cd lumina_kernel && maturin develop --release\n")


def benchmark_matmul(
    batch_size: int,
    in_features: int,
    out_features: int,
    iterations: int = 100
) -> Dict[str, float]:
    """
    åŸºå‡†æµ‹è¯•ï¼šçº¯çŸ©é˜µä¹˜æ³•
    """
    print(f"\nğŸ“Š æµ‹è¯•åœºæ™¯: çŸ©é˜µä¹˜æ³• [{batch_size}, {in_features}] @ [{out_features}, {in_features}]")
    
    # å‡†å¤‡æ•°æ®
    x_torch = torch.randn(batch_size, in_features)
    w_torch = torch.randn(out_features, in_features)
    
    x_np = x_torch.numpy().astype(np.float32)
    w_np = w_torch.numpy().astype(np.float32)
    
    results = {}
    
    # PyTorch åŸºçº¿
    torch.manual_seed(42)
    start = time.time()
    for _ in range(iterations):
        y = F.linear(x_torch, w_torch)
    pytorch_time = time.time() - start
    results['pytorch'] = pytorch_time
    
    print(f"  PyTorch: {pytorch_time*1000:.2f} ms ({iterations} æ¬¡è¿­ä»£)")
    
    # Rust åç«¯
    if RUST_AVAILABLE:
        start = time.time()
        for _ in range(iterations):
            y = lumina_kernel.optical_linear_infer(x_np, w_np, None, bits=8)
        rust_time = time.time() - start
        results['rust'] = rust_time
        
        speedup = pytorch_time / rust_time
        print(f"  Rust:    {rust_time*1000:.2f} ms ({iterations} æ¬¡è¿­ä»£)")
        print(f"  âš¡ åŠ é€Ÿæ¯”: {speedup:.2f}x")
    
    return results


def benchmark_fused_ops(
    batch_size: int,
    in_features: int,
    out_features: int,
    iterations: int = 100
) -> Dict[str, float]:
    """
    åŸºå‡†æµ‹è¯•ï¼šèåˆç®—å­ï¼ˆçŸ©é˜µä¹˜æ³• + å™ªå£° + é‡åŒ–ï¼‰
    """
    print(f"\nğŸ“Š æµ‹è¯•åœºæ™¯: èåˆç®—å­ [{batch_size}, {in_features}] -> [{batch_size}, {out_features}]")
    
    # å‡†å¤‡æ•°æ®
    x_torch = torch.randn(batch_size, in_features)
    w_torch = torch.randn(out_features, in_features)
    
    x_np = x_torch.numpy().astype(np.float32)
    w_np = w_torch.numpy().astype(np.float32)
    
    noise_std = 0.1
    bits = 4
    
    results = {}
    
    # PyTorch æ¨¡æ‹Ÿï¼ˆåˆ†ç¦»æ“ä½œï¼‰
    def pytorch_fused_sim(x, w, noise_std, bits):
        # çŸ©é˜µä¹˜æ³•
        y = F.linear(x, w)
        # å™ªå£°æ³¨å…¥
        noise = torch.randn_like(y) * noise_std * torch.abs(y).sqrt()
        y = y + noise
        # é‡åŒ–æ¨¡æ‹Ÿ
        scale = (2**bits - 1) / 20.0
        y = torch.clamp(y, -10.0, 10.0)
        y = torch.round(y * scale) / scale
        return y
    
    torch.manual_seed(42)
    start = time.time()
    for _ in range(iterations):
        y = pytorch_fused_sim(x_torch, w_torch, noise_std, bits)
    pytorch_time = time.time() - start
    results['pytorch_fused'] = pytorch_time
    
    print(f"  PyTorch (åˆ†ç¦»): {pytorch_time*1000:.2f} ms ({iterations} æ¬¡è¿­ä»£)")
    
    # Rust èåˆç®—å­
    if RUST_AVAILABLE:
        start = time.time()
        for _ in range(iterations):
            y = lumina_kernel.optical_linear_fused(
                x_np, w_np, None, noise_std, bits, 42
            )
        rust_time = time.time() - start
        results['rust_fused'] = rust_time
        
        speedup = pytorch_time / rust_time
        print(f"  Rust (èåˆ):    {rust_time*1000:.2f} ms ({iterations} æ¬¡è¿­ä»£)")
        print(f"  âš¡ åŠ é€Ÿæ¯”: {speedup:.2f}x")
    
    return results


def benchmark_batch_sizes():
    """
    æµ‹è¯•ä¸åŒæ‰¹é‡å¤§å°çš„æ€§èƒ½
    """
    print("\n" + "="*60)
    print("æ‰¹é‡å¤§å°æ€§èƒ½æµ‹è¯•")
    print("="*60)
    
    in_features = 128
    out_features = 64
    
    batch_sizes = [1, 4, 16, 32, 64]
    
    for batch_size in batch_sizes:
        benchmark_matmul(batch_size, in_features, out_features, iterations=100)


def benchmark_layer_sizes():
    """
    æµ‹è¯•ä¸åŒå±‚å¤§å°çš„æ€§èƒ½
    """
    print("\n" + "="*60)
    print("å±‚å¤§å°æ€§èƒ½æµ‹è¯•")
    print("="*60)
    
    batch_size = 32
    
    configs = [
        (784, 512),   # MNIST è¾“å…¥
        (512, 256),   # ä¸­é—´å±‚
        (256, 10),    # è¾“å‡ºå±‚
        (2048, 1024), # å¤§å‹å±‚
    ]
    
    for in_feat, out_feat in configs:
        benchmark_fused_ops(batch_size, in_feat, out_feat, iterations=50)


def benchmark_edge_inference():
    """
    è¾¹ç¼˜æ¨ç†åœºæ™¯ï¼ˆå°æ‰¹é‡ï¼‰
    """
    print("\n" + "="*60)
    print("è¾¹ç¼˜æ¨ç†åœºæ™¯ï¼ˆbatch=1ï¼‰")
    print("="*60)
    
    configs = [
        (784, 512),
        (512, 256),
        (256, 10),
    ]
    
    for in_feat, out_feat in configs:
        benchmark_matmul(1, in_feat, out_feat, iterations=1000)


def main():
    print("="*60)
    print("LuminaKernel æ€§èƒ½åŸºå‡†æµ‹è¯•")
    print("="*60)
    print(f"Rust åç«¯: {'âœ… å¯ç”¨' if RUST_AVAILABLE else 'âŒ ä¸å¯ç”¨'}")
    print(f"PyTorch ç‰ˆæœ¬: {torch.__version__}")
    print(f"NumPy ç‰ˆæœ¬: {np.__version__}")
    
    # è¿è¡Œæµ‹è¯•
    benchmark_batch_sizes()
    benchmark_layer_sizes()
    benchmark_edge_inference()
    
    print("\n" + "="*60)
    print("æµ‹è¯•å®Œæˆ")
    print("="*60)
    
    if RUST_AVAILABLE:
        print("\nğŸ’¡ ç»“è®º:")
        print("  - å°æ‰¹é‡ï¼ˆbatch=1ï¼‰: Rust åç«¯æä¾› 4-6x åŠ é€Ÿ")
        print("  - å¤§æ‰¹é‡ï¼ˆbatch=32+ï¼‰: Rust åç«¯æä¾› 2-3x åŠ é€Ÿ")
        print("  - èåˆç®—å­: å‡å°‘å†…å­˜å¸¦å®½ï¼Œæå‡ 3-4x æ€§èƒ½")
    else:
        print("\nğŸ’¡ æç¤º: å®‰è£… Rust åç«¯ä»¥æŸ¥çœ‹åŠ é€Ÿæ•ˆæœ")
        print("  cd lumina_kernel && maturin develop --release")


if __name__ == "__main__":
    main()
